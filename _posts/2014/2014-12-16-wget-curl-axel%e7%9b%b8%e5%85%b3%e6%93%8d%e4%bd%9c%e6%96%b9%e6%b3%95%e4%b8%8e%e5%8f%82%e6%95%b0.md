---
layout: post
title: wget curl axel相关操作方法与参数
date: 2014-12-16 15:02
author: admin
comments: true
categories: []
---
wget:
中文详细说明（参数什么的很多很全）：http://forum.ubuntu.org.cn/viewtopic.php?f=73&t=213029
这个也不错：  http://os.51cto.com/art/201002/183100.htm
比如，下载整个网站以便底线阅读：http://forum.ubuntu.org.cn/viewtopic.php?f=73&t=150608&start=0
使用wget为Ubuntu更新加速：
http://forum.ubuntu.org.cn/viewtopic.php?f=113&t=226617&start=0&sid=ac531d90b008535e867c1e8355e5cf01
 
curl:
这个貌似没有wget应用那么广，不过有集合或序列时还是蛮高效的：http://curl.haxx.se/docs/manpage.html
 
axel,aria2:
虽然有了前面这两个功能强大的工具，但它们都不能多线程并发下载资源，在下载大型文件时，我们更多时候会选择axel或aria2：
http://aria2.sourceforge.net/manual/en/html/aria2c.html#options
 
 
关于单线程和多线程的速度比拼问题，也就是大家经常讨论的wget 和 axel 的下载速度比较；在网上偶然间看到如下解释，觉得有道理，
就粘贴上来了：
 
 
首先，为什么单线程会比多线程慢？ 

下载时候，速度受两方面限制，你的下行带宽和服务器的上行带宽(说白了就是你的下载速度和服务器的上传速度) 

分情况来看 

情况a.下载速度>服务器带宽 

比如你的下载速度是100k，服务器则只能提供20k的带宽。于是你用单线程下载，就只有20k的速度 
但问题是，一般来说，服务器的最大带宽肯定不止20k，只是服务器端会限制单个访问的带宽（带宽都给一个访问者用了，别人用什么去）。这时多线程下载就可以同时n次访问服务器，获得20k*n的速度，当然，不会大于100k。 

情况b.下载速度<=服务器带宽 

你的下载速度是100k，而服务器则能提供>100k的带宽，这个时候，你用单线程就能达到100k的极限速度，而多线程同时维护多个访问连接，会把你100k的下载带宽花费在一些没用的地方，反而会比单线程慢。 

前几年，情况a比较多见，所以多线程比较牛x，这几年，随着硬件成本降低，国内网络基础设施建设发展，还有p2p的分流，情况b就多了起来，像我是512k的adsl，只有50k的下行带宽，基本上都是情况b 

这样就可以理解，为什么wget经常不比多线程慢的原因了 

另外还有一个问题，就是服务器比较远的情况，比如国外的服务器，由于包传送中的延迟与丢失，服务器可能提供了很大的带宽，但是到了下载端，就要缩水不少，这时就等于情况a了。不过另一方面，发达国家服务器带宽通常比较大（人家有钱$_$），这方面会有所弥补，比如我在ubuntu.com下iso，用wget就能达到下载速度的极限。 

所以现在开太多的线程下载，不仅浪费你的下载带宽，也增加了你的机器和服务器的负荷，完全没有必要。 

推荐先用wget下下看，如果能到极限就直接下，不能到极限的话，就做个除法，计算下开几个线程合适再下。
